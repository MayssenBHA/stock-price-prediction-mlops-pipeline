{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models.signature import infer_signature\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# --- Setup MLflow experiment (same as ARIMA notebook) ---\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\") \n",
    "mlflow.set_experiment(\"model_experiment\")\n",
    "print(\"MLflow experiment 'model_experiment' is set up and ready for tracking.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from model import walk_forward_validation\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./vgi2.csv')\n",
    "data.index = pd.to_datetime(data['date'], format='%Y-%m-%d')\n",
    "data.pop('date')\n",
    "data = pd.DataFrame(data, dtype=np.float64)\n",
    "\n",
    "\n",
    "# train_split = data.index.get_loc('2021-10-29')\n",
    "# close = data.pop('close')\n",
    "# data.insert(5, 'close', close)\n",
    "# data1 = data.iloc[809:, 0]  #3501, 5\n",
    "# residuals = pd.read_csv('./ARIMA_residuals1.csv')\n",
    "# residuals.index = pd.to_datetime(residuals['date'])  #trade_date\n",
    "# residuals.pop('date')\n",
    "# merge_data = pd.merge(data, residuals, on='date')\n",
    "# #merge_data = merge_data.drop(labels='2007-01-04', axis=0)\n",
    "# time = pd.Series(data.index[810:]) # thay vì 809, vị trí đầu tiên sẽ bị remove vì nan value dó đó index bị lùi 1 step\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ARIMA residuals and merge with close, open, high, low, nmVolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = pd.read_csv('./ARIMA_residuals1.csv')\n",
    "residuals.index = pd.to_datetime(residuals['date'])  #trade_date\n",
    "residuals.pop('date')\n",
    "merge_data = pd.merge(data, residuals, on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = merge_data.rename(columns={'0':'Residual'})\n",
    "merge_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting Train - Validation - Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = merge_data[merge_data.index <= '2020-11-24']\n",
    "valid = merge_data[(merge_data.index <= '2021-10-29')&(merge_data.index > '2020-11-24')]\n",
    "test_set = merge_data[(merge_data.index <= '2021-12-31')&(merge_data.index > '2021-10-29')]\n",
    "training_set = pd.concat([train, valid], axis=0)\n",
    "print('train shape:', train.shape)\n",
    "print('validation shape:', valid.shape)\n",
    "print('test shape:', test_set.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Predictions from ARIMA model on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lt = pd.read_csv('./ARIMA.csv')\n",
    "Lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lt = Lt.drop('date', axis=1)\n",
    "Lt = np.array(Lt)\n",
    "Lt = Lt.flatten().tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Predictions from ARIMA model on Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt = pd.read_csv('./ARIMA_Validation.csv')\n",
    "Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt = Vt.drop('date', axis=1)\n",
    "Vt = np.array(Vt)\n",
    "Vt = Vt.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to supervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_valiation(train_series, n_valid, n_in, n_out):\n",
    "    values = train_series.values\n",
    "    supervised_data = series_to_supervised(values, n_in, n_out)\n",
    "    print('supervised_data', supervised_data)\n",
    "    idx = train_series.shape[0] - n_valid\n",
    "    train, valid = supervised_data.loc[:idx, :], supervised_data.loc[idx:, :]\n",
    "    return train, valid, supervised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_test(series, n_test, n_in, n_out):\n",
    "    values = series.values\n",
    "    supervised_data = series_to_supervised(values, n_in, n_out)\n",
    "    print('supervised_data', supervised_data)\n",
    "    idx = series.shape[0] - n_test\n",
    "    train, test = supervised_data.loc[:idx, :], supervised_data.loc[idx:, :]\n",
    "    return train, test, supervised_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train and Valid set will be split from Traing_set for Validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import *\n",
    "n_timestamp = 1\n",
    "\n",
    "train_supervised, valid_supervised, supervised_data_validation = prepare_data_valiation(training_set, n_valid=valid.shape[0], n_in=n_timestamp, n_out=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_supervised.shape)\n",
    "print(valid_supervised.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Spliting for Testing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import *\n",
    "n_timestamp = 1\n",
    "\n",
    "training_set_supervised, test_supervised, supervised_data_test = prepare_data_test(merge_data, n_test=test_set.shape[0], n_in=n_timestamp, n_out=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(training_set_supervised.shape)\n",
    "print(test_supervised.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_data_test.tail(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_supervised.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min Max Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data_sc = MinMaxScaler(feature_range=(0, 1))\n",
    "train_scaled = data_sc.fit_transform(train_supervised)\n",
    "valid_scaled = data_sc.transform(valid_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sc2 = MinMaxScaler(feature_range=(0, 1))\n",
    "training_set_scaled = data_sc2.fit_transform(training_set_supervised)\n",
    "test_set_scaled = data_sc2.transform(test_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = pd.DataFrame(train_scaled, columns=train_supervised.columns)\n",
    "valid_scaled = pd.DataFrame(valid_scaled, columns=valid_supervised.columns)\n",
    "\n",
    "training_set_scaled = pd.DataFrame(training_set_scaled, columns=training_set_supervised.columns)\n",
    "test_set_scaled = pd.DataFrame(test_set_scaled, columns=test_supervised.columns)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Model with the data supervised from merge_data (close, open, high, low, nmVolume, Residual)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ARIMA-XGBoost Model: XGBoost will predict the residuals, then plus ARIMA predictions into the final predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Validation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = valid.index\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, yhat = walk_forward_validation(train_scaled, valid_scaled)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time, y, label='Residuals')\n",
    "plt.plot(time, yhat, label='Predicted Residuals')\n",
    "plt.title('ARIMA+XGBoost: Residuals Prediction')\n",
    "plt.xlabel('Time', fontsize=12, verticalalignment='top')\n",
    "plt.ylabel('Residuals', fontsize=14, horizontalalignment='center')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min = train_supervised.min(axis=0)[5] # 5 means residual position\n",
    "train_max = train_supervised.max(axis=0)[5]\n",
    "print(train_min)\n",
    "print(train_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid set\n",
    "y_hat_valid_unscaled = np.asarray(yhat)*(train_max - train_min) + train_min\n",
    "y_valid_unscaled = np.asarray(y)*(train_max - train_min) + train_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluation_metric(y_test,y_hat):\n",
    "evaluation_metric(y_valid_unscaled, y_hat_valid_unscaled )\n",
    "\n",
    "# def GetMAPE(y_hat, y_test):\n",
    "GetMAPE(y_hat_valid_unscaled, y_valid_unscaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Tracking: ARIMA-XGBoost Hybrid Model (Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start MLflow run for ARIMA-XGBoost Hybrid model\n",
    "mlflow_hybrid_run_id = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"ARIMA_XGBoost_Hybrid\") as run:\n",
    "    mlflow_hybrid_run_id = run.info.run_id\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"ARIMA_XGBoost_Hybrid\")\n",
    "    mlflow.log_param(\"arima_order\", \"(0,1,0)\")\n",
    "    mlflow.log_param(\"n_timestamp\", n_timestamp)\n",
    "    mlflow.log_param(\"scaler_type\", \"MinMaxScaler\")\n",
    "    mlflow.log_param(\"scaler_range\", \"(0, 1)\")\n",
    "    mlflow.log_param(\"features\", \"close, open, high, low, nmVolume, Residual\")\n",
    "    \n",
    "    # Log XGBoost residual prediction metrics (validation)\n",
    "    val_residual_mse = metrics.mean_squared_error(y_valid_unscaled, y_hat_valid_unscaled)\n",
    "    val_residual_rmse = np.sqrt(val_residual_mse)\n",
    "    val_residual_mae = metrics.mean_absolute_error(y_valid_unscaled, y_hat_valid_unscaled)\n",
    "    val_residual_r2 = metrics.r2_score(y_valid_unscaled, y_hat_valid_unscaled)\n",
    "    val_residual_mape = GetMAPE(y_hat_valid_unscaled, y_valid_unscaled)\n",
    "    \n",
    "    mlflow.log_metric(\"val_residual_mse\", val_residual_mse)\n",
    "    mlflow.log_metric(\"val_residual_rmse\", val_residual_rmse)\n",
    "    mlflow.log_metric(\"val_residual_mae\", val_residual_mae)\n",
    "    mlflow.log_metric(\"val_residual_r2\", val_residual_r2)\n",
    "    mlflow.log_metric(\"val_residual_mape\", val_residual_mape)\n",
    "    \n",
    "    print(f\"✅ ARIMA-XGBoost Hybrid (Residual Validation) logged to MLflow - Run ID: {run.info.run_id}\")\n",
    "    print(f\"   Residual Validation RMSE: {val_residual_rmse:.5f}, MAPE: {val_residual_mape:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalpredicted_stock_price = [i + j for i, j in zip(Vt, y_hat_valid_unscaled)]\n",
    "#print('final', finalpredicted_stock_price)\n",
    "evaluation_metric(valid.iloc[:,0], finalpredicted_stock_price)\n",
    "\n",
    "print('MAPE_ARIMA-XGBoost_Validation:', GetMAPE(finalpredicted_stock_price, valid.iloc[:,0]), '%')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(time, valid.iloc[:,0], label='Stock Price')\n",
    "plt.plot(time, finalpredicted_stock_price, label='Predicted Stock Price')\n",
    "plt.title(f'ARIMA+XGBoost: Stock Price Prediction on Validation, n_timestamp = {n_timestamp}')\n",
    "\n",
    "plt.xlabel('Time', fontsize=12, verticalalignment='top')\n",
    "plt.ylabel('Close', fontsize=14, horizontalalignment='center')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# n_timestamp = 0\n",
    "# MSE: 0.92375\n",
    "# RMSE: 0.96112\n",
    "# MAE: 0.56679\n",
    "# R2: 0.95247\n",
    "# MAPE_ARIMA-XGBoost_Validation: 1.5584695259033352 %\n",
    "\n",
    "# n_timestamp = 1\n",
    "# MSE: 0.83644\n",
    "# RMSE: 0.91457\n",
    "# MAE: 0.57544\n",
    "# R2: 0.95696\n",
    "# MAPE_ARIMA-XGBoost_Validation: 1.5858401261736605 %\n",
    "\n",
    "# n_timestamp = 6\n",
    "# MSE: 1.11843\n",
    "# RMSE: 1.05756\n",
    "# MAE: 0.65351\n",
    "# R2: 0.94245\n",
    "# MAPE_ARIMA-XGBoost_Validation: 1.8010548292247548 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue hybrid model run - log final validation metrics\n",
    "with mlflow.start_run(run_id=mlflow_hybrid_run_id) as run:\n",
    "    \n",
    "    # Calculate final hybrid validation metrics\n",
    "    val_mse = metrics.mean_squared_error(valid.iloc[:,0], finalpredicted_stock_price)\n",
    "    val_rmse = np.sqrt(val_mse)\n",
    "    val_mae = metrics.mean_absolute_error(valid.iloc[:,0], finalpredicted_stock_price)\n",
    "    val_r2 = metrics.r2_score(valid.iloc[:,0], finalpredicted_stock_price)\n",
    "    val_mape = GetMAPE(finalpredicted_stock_price, valid.iloc[:,0])\n",
    "    \n",
    "    # Log final validation metrics\n",
    "    mlflow.log_metric(\"val_mse\", val_mse)\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "    mlflow.log_metric(\"val_mae\", val_mae)\n",
    "    mlflow.log_metric(\"val_r2\", val_r2)\n",
    "    mlflow.log_metric(\"val_mape\", val_mape)\n",
    "    \n",
    "    print(f\"✅ ARIMA-XGBoost Hybrid (Final Validation) logged to MLflow\")\n",
    "    print(f\"   Final Validation RMSE: {val_rmse:.5f}, MAPE: {val_mape:.3f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Plus XGBoost residual prediction with ARIMA predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Testing Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_test = test_set.index\n",
    "y_test, yhat_test = walk_forward_validation(training_set_scaled, test_set_scaled)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_test, y_test, label='Residuals')\n",
    "plt.plot(time_test, yhat_test, label='Predicted Residuals')\n",
    "plt.title('ARIMA+XGBoost: Residuals Prediction')\n",
    "plt.xlabel('Time', fontsize=12, verticalalignment='top')\n",
    "plt.ylabel('Residuals', fontsize=14, horizontalalignment='center')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_min = training_set_supervised.min(axis=0)[5] # 5 means residual position\n",
    "training_set_max = training_set_supervised.max(axis=0)[5]\n",
    "print(training_set_min)\n",
    "print(training_set_max)\n",
    "\n",
    "# Valid set\n",
    "y_hat_test_unscaled = np.asarray(yhat_test)*(training_set_max - training_set_min) + training_set_min\n",
    "y_test_unscaled = np.asarray(y_test)*(training_set_max - training_set_min) + training_set_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluation_metric(y_test,y_hat):\n",
    "evaluation_metric(y_test_unscaled, y_hat_test_unscaled)\n",
    "\n",
    "# def GetMAPE(y_hat, y_test):\n",
    "GetMAPE(y_hat_test_unscaled, y_test_unscaled)\n",
    "\n",
    "# MSE: 0.36510\n",
    "# RMSE: 0.60423\n",
    "# MAE: 0.44403\n",
    "# R2: 0.27840\n",
    "# 157.67322619794388"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue hybrid model run - log test residual metrics\n",
    "with mlflow.start_run(run_id=mlflow_hybrid_run_id) as run:\n",
    "    \n",
    "    # Log test residual metrics\n",
    "    test_residual_mse = metrics.mean_squared_error(y_test_unscaled, y_hat_test_unscaled)\n",
    "    test_residual_rmse = np.sqrt(test_residual_mse)\n",
    "    test_residual_mae = metrics.mean_absolute_error(y_test_unscaled, y_hat_test_unscaled)\n",
    "    test_residual_r2 = metrics.r2_score(y_test_unscaled, y_hat_test_unscaled)\n",
    "    test_residual_mape = GetMAPE(y_hat_test_unscaled, y_test_unscaled)\n",
    "    \n",
    "    mlflow.log_metric(\"test_residual_mse\", test_residual_mse)\n",
    "    mlflow.log_metric(\"test_residual_rmse\", test_residual_rmse)\n",
    "    mlflow.log_metric(\"test_residual_mae\", test_residual_mae)\n",
    "    mlflow.log_metric(\"test_residual_r2\", test_residual_r2)\n",
    "    mlflow.log_metric(\"test_residual_mape\", test_residual_mape)\n",
    "    \n",
    "    print(f\"✅ ARIMA-XGBoost Hybrid (Residual Test) logged to MLflow\")\n",
    "    print(f\"   Residual Test RMSE: {test_residual_rmse:.5f}, MAPE: {test_residual_mape:.3f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Plus XGBoost residual prediction with ARIMA predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finalpredicted_stock_price2 = [i + j for i, j in zip(Lt, y_hat_test_unscaled)]\n",
    "#print('final', finalpredicted_stock_price)\n",
    "evaluation_metric(test_set.iloc[:, 0], finalpredicted_stock_price2)\n",
    "\n",
    "print('MAPE_ARIMA-XGBoost_Testing:', GetMAPE(finalpredicted_stock_price2, test_set.iloc[:, 0]), '%')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(time_test, test_set.iloc[:, 0], label='Stock Price')\n",
    "plt.plot(time_test, finalpredicted_stock_price2, label='Predicted Stock Price')\n",
    "plt.title(f'ARIMA+XGBoost: Stock Price Prediction on Test set, n_timestamp = {n_timestamp}')\n",
    "plt.xlabel('Time', fontsize=12, verticalalignment='top')\n",
    "plt.ylabel('Close', fontsize=14, horizontalalignment='center')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# n_timestamp = 6\n",
    "# MSE: 0.36696\n",
    "# RMSE: 0.60577\n",
    "# MAE: 0.44506\n",
    "# R2: 0.93019\n",
    "\n",
    "# n_timestamp = 1\n",
    "# MSE: 0.20460\n",
    "# RMSE: 0.45233\n",
    "# MAE: 0.32653\n",
    "# R2: 0.96108\n",
    "# MAPE_ARIMA-XGBoost_Testing: 0.9469896700985768 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue hybrid model run - log final test metrics and save model artifacts\n",
    "with mlflow.start_run(run_id=mlflow_hybrid_run_id) as run:\n",
    "    \n",
    "    # Calculate final test metrics\n",
    "    test_mse = metrics.mean_squared_error(test_set.iloc[:, 0], finalpredicted_stock_price2)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    test_mae = metrics.mean_absolute_error(test_set.iloc[:, 0], finalpredicted_stock_price2)\n",
    "    test_r2 = metrics.r2_score(test_set.iloc[:, 0], finalpredicted_stock_price2)\n",
    "    test_mape = GetMAPE(finalpredicted_stock_price2, test_set.iloc[:, 0])\n",
    "    \n",
    "    # Log final test metrics\n",
    "    mlflow.log_metric(\"test_mse\", test_mse)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "    mlflow.log_metric(\"test_mae\", test_mae)\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_mape\", test_mape)\n",
    "    \n",
    "    # Save and log artifacts\n",
    "    # Save scalers\n",
    "    joblib.dump(data_sc, 'scaler_validation.pkl')\n",
    "    joblib.dump(data_sc2, 'scaler_test.pkl')\n",
    "    mlflow.log_artifact('scaler_validation.pkl', artifact_path='scalers')\n",
    "    mlflow.log_artifact('scaler_test.pkl', artifact_path='scalers')\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'n_timestamp': n_timestamp,\n",
    "        'train_min': float(train_min),\n",
    "        'train_max': float(train_max),\n",
    "        'training_set_min': float(training_set_min),\n",
    "        'training_set_max': float(training_set_max),\n",
    "        'feature_columns': list(train_supervised.columns),\n",
    "        'arima_order': '(0,1,0)'\n",
    "    }\n",
    "    with open('model_metadata.json', 'w') as f:\n",
    "        import json\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    mlflow.log_artifact('model_metadata.json', artifact_path='metadata')\n",
    "    \n",
    "    # Log ARIMA model reference\n",
    "    mlflow.log_artifact('model_ARIMA.pkl', artifact_path='model')\n",
    "    mlflow.log_artifact('ARIMA_residuals1.csv', artifact_path='data')\n",
    "    \n",
    "    print(f\"✅ ARIMA-XGBoost Hybrid (Final Test & Artifacts) logged to MLflow - Run ID: {run.info.run_id}\")\n",
    "    print(f\"   Final Test RMSE: {test_rmse:.5f}, MAPE: {test_mape:.3f}%\")\n",
    "    print(f\"   Artifacts saved: scalers, metadata, ARIMA model, residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Complete Hybrid Model as Custom MLflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMAResults\n",
    "\n",
    "class ARIMAXGBoostHybridModel(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"\n",
    "    Custom MLflow model for ARIMA-XGBoost Hybrid\n",
    "    \n",
    "    Input: DataFrame with columns ['close', 'open', 'high', 'low', 'nmVolume'] and DatetimeIndex\n",
    "    Output: Array of predicted stock prices\n",
    "    \"\"\"\n",
    "    \n",
    "    def load_context(self, context):\n",
    "        \"\"\"Load all model components\"\"\"\n",
    "        import json\n",
    "        \n",
    "        # Load ARIMA model\n",
    "        self.arima_model = ARIMAResults.load(context.artifacts[\"arima_model\"])\n",
    "        \n",
    "        # Load XGBoost model (we'll save it in next cell)\n",
    "        self.xgb_model = pickle.load(open(context.artifacts[\"xgboost_model\"], 'rb'))\n",
    "        \n",
    "        # Load scaler\n",
    "        self.scaler = joblib.load(context.artifacts[\"scaler\"])\n",
    "        \n",
    "        # Load metadata\n",
    "        with open(context.artifacts[\"metadata\"]) as f:\n",
    "            self.metadata = json.load(f)\n",
    "        \n",
    "        self.n_timestamp = self.metadata['n_timestamp']\n",
    "        self.train_min = self.metadata['training_set_min']\n",
    "        self.train_max = self.metadata['training_set_max']\n",
    "        \n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"\n",
    "        Predict stock prices using ARIMA + XGBoost\n",
    "        \n",
    "        Parameters:\n",
    "        - model_input: DataFrame with ['close', 'open', 'high', 'low', 'nmVolume']\n",
    "        \n",
    "        Returns:\n",
    "        - Array of predicted close prices\n",
    "        \"\"\"\n",
    "        # Step 1: Generate ARIMA predictions (walk-forward)\n",
    "        arima_predictions = []\n",
    "        history = list(model_input['close'].values)\n",
    "        \n",
    "        for i in range(len(model_input)):\n",
    "            # Fit ARIMA on history up to current point\n",
    "            temp_arima = sm.tsa.ARIMA(history[:i+1], order=(0, 1, 0))\n",
    "            temp_arima_fit = temp_arima.fit()\n",
    "            forecast = temp_arima_fit.forecast(steps=1)\n",
    "            arima_predictions.append(float(forecast[0]))\n",
    "        \n",
    "        # Step 2: Calculate residuals\n",
    "        residuals = model_input['close'].values - np.array(arima_predictions)\n",
    "        residuals_df = pd.DataFrame(residuals, columns=['Residual'], index=model_input.index)\n",
    "        \n",
    "        # Step 3: Merge with features\n",
    "        merge_data = pd.concat([model_input, residuals_df], axis=1)\n",
    "        \n",
    "        # Step 4: Convert to supervised format\n",
    "        values = merge_data.values\n",
    "        supervised_data = series_to_supervised(values, n_in=self.n_timestamp, n_out=1)\n",
    "        \n",
    "        # Step 5: Scale\n",
    "        scaled_data = self.scaler.transform(supervised_data)\n",
    "        \n",
    "        # Step 6: XGBoost predicts residuals\n",
    "        X_features = scaled_data[:, :-1]  # All except last column\n",
    "        # Use .predict() directly with XGBRegressor (no DMatrix needed for pickled models)\n",
    "        residual_predictions_scaled = self.xgb_model.predict(X_features)\n",
    "        \n",
    "        # Step 7: Unscale residuals\n",
    "        residual_predictions = (residual_predictions_scaled * (self.train_max - self.train_min) + self.train_min)\n",
    "        \n",
    "        # Step 8: Final prediction = ARIMA + XGBoost residuals\n",
    "        # Adjust arima_predictions to match length after supervised conversion\n",
    "        arima_preds_adjusted = arima_predictions[self.n_timestamp:]\n",
    "        final_predictions = np.array(arima_preds_adjusted) + residual_predictions\n",
    "        \n",
    "        return final_predictions\n",
    "\n",
    "print(\"✅ ARIMAXGBoostHybridModel class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final XGBoost model and save complete hybrid model\n",
    "from model import walk_forward_validation\n",
    "\n",
    "# We need to extract the trained XGBoost model from walk_forward_validation\n",
    "# For now, let's train a final XGBoost model on all training data\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "# Prepare final training data\n",
    "train_X = training_set_scaled.iloc[:, :-1]\n",
    "train_y = training_set_scaled.iloc[:, -1]\n",
    "\n",
    "# Train final XGBoost model\n",
    "final_xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "final_xgb_model.fit(train_X, train_y)\n",
    "\n",
    "# Save XGBoost model\n",
    "with open('xgboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(final_xgb_model, f)\n",
    "\n",
    "print(\"✅ Final XGBoost model trained and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the complete hybrid model to MLflow\n",
    "with mlflow.start_run(run_id=mlflow_hybrid_run_id) as run:\n",
    "    \n",
    "    # Define artifacts dictionary\n",
    "    artifacts = {\n",
    "        \"arima_model\": \"model_ARIMA.pkl\",\n",
    "        \"xgboost_model\": \"xgboost_model.pkl\",\n",
    "        \"scaler\": \"scaler_test.pkl\",\n",
    "        \"metadata\": \"model_metadata.json\"\n",
    "    }\n",
    "    \n",
    "    # Create sample input for signature\n",
    "    sample_input = test_set[['close', 'open', 'high', 'low', 'nmVolume']].head(10)\n",
    "    \n",
    "    # Log the custom model\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"arima_xgboost_hybrid_model\",\n",
    "        python_model=ARIMAXGBoostHybridModel(),\n",
    "        artifacts=artifacts,\n",
    "        conda_env={\n",
    "            'channels': ['defaults', 'conda-forge'],\n",
    "            'dependencies': [\n",
    "                'python=3.10',\n",
    "                'pip',\n",
    "                {\n",
    "                    'pip': [\n",
    "                        'mlflow',\n",
    "                        'pandas',\n",
    "                        'numpy',\n",
    "                        'scikit-learn',\n",
    "                        'xgboost',\n",
    "                        'statsmodels',\n",
    "                        'joblib'\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            'name': 'arima_xgboost_env'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Complete ARIMA-XGBoost Hybrid Model saved to MLflow!\")\n",
    "    print(f\"   Run ID: {run.info.run_id}\")\n",
    "    print(f\"   Model URI: runs:/{run.info.run_id}/arima_xgboost_hybrid_model\")\n",
    "    print(f\"\\n📊 Model Summary:\")\n",
    "    print(f\"   - Input: DataFrame with ['close', 'open', 'high', 'low', 'nmVolume']\")\n",
    "    print(f\"   - Output: Array of predicted close prices\")\n",
    "    print(f\"   - Components: ARIMA(0,1,0) + XGBoost + MinMaxScaler\")\n",
    "    print(f\"   - Test RMSE: {test_rmse:.5f}\")\n",
    "    print(f\"   - Test MAPE: {test_mape:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Loading and Using the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load the saved model and make predictions\n",
    "print(\"🔄 Loading saved hybrid model from MLflow...\")\n",
    "\n",
    "# Load the model\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"runs:/{mlflow_hybrid_run_id}/arima_xgboost_hybrid_model\")\n",
    "\n",
    "# Prepare input data (use vgi2.csv format)\n",
    "test_input = pd.read_csv('./vgi2.csv')\n",
    "test_input.index = pd.to_datetime(test_input['date'], format='%Y-%m-%d')\n",
    "test_input = test_input.drop('date', axis=1)\n",
    "test_input = pd.DataFrame(test_input, dtype=np.float64)\n",
    "\n",
    "# Get test period data\n",
    "test_input_sample = test_input[(test_input.index > '2021-10-29') & (test_input.index <= '2021-12-31')]\n",
    "test_input_sample = test_input_sample[['close', 'open', 'high', 'low', 'nmVolume']]\n",
    "\n",
    "print(f\"📥 Input shape: {test_input_sample.shape}\")\n",
    "print(f\"   Predicting for period: {test_input_sample.index[0]} to {test_input_sample.index[-1]}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions_loaded = loaded_model.predict(test_input_sample)\n",
    "\n",
    "print(f\"\\n📤 Output shape: {predictions_loaded.shape}\")\n",
    "print(f\"   Sample predictions: {predictions_loaded[:5]}\")\n",
    "\n",
    "# Verify predictions match\n",
    "print(f\"\\n✅ Model loaded and predictions generated successfully!\")\n",
    "print(f\"   Use this model with any vgi2.csv formatted data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 MLflow Experiment Summary\n",
    "\n",
    "All models have been tracked in the **\"model_experiment\"** experiment with consistent metric names for easy comparison.\n",
    "\n",
    "### **Models Saved:**\n",
    "\n",
    "#### **1. Persistence Model (Baseline)**\n",
    "- **Metrics**: `val_mse`, `val_rmse`, `val_mae`, `val_r2`, `val_mape`, `test_mse`, `test_rmse`, `test_mae`, `test_r2`, `test_mape`\n",
    "- **Artifacts**: None\n",
    "\n",
    "#### **2. ARIMA Model**\n",
    "- **Metrics**: Same as above\n",
    "- **Artifacts**: \n",
    "  - `model_ARIMA.pkl` - Fitted ARIMA model\n",
    "  - `ARIMA_residuals1.csv` - Residuals for training\n",
    "  - `ARIMA_Validation.csv` - Validation predictions\n",
    "  - `ARIMA.csv` - Test predictions\n",
    "\n",
    "#### **3. ARIMA-XGBoost Hybrid Model** ⭐\n",
    "- **Metrics**: \n",
    "  - Residual metrics: `val_residual_mse`, `val_residual_rmse`, etc.\n",
    "  - Final metrics: `val_mse`, `val_rmse`, `val_mae`, `val_r2`, `val_mape`, `test_mse`, `test_rmse`, `test_mae`, `test_r2`, `test_mape`\n",
    "- **Artifacts**:\n",
    "  - `arima_xgboost_hybrid_model/` - Complete deployable model (MLflow PythonModel)\n",
    "  - `model_ARIMA.pkl` - ARIMA component\n",
    "  - `xgboost_model.pkl` - XGBoost component\n",
    "  - `scaler_validation.pkl`, `scaler_test.pkl` - Scalers\n",
    "  - `model_metadata.json` - Configuration metadata\n",
    "\n",
    "### **Saved Hybrid Model Usage:**\n",
    "\n",
    "```python\n",
    "# Load model\n",
    "model = mlflow.pyfunc.load_model(\"runs:/<run_id>/arima_xgboost_hybrid_model\")\n",
    "\n",
    "# Input: DataFrame with columns ['close', 'open', 'high', 'low', 'nmVolume']\n",
    "input_data = pd.read_csv('vgi2.csv')\n",
    "# ... preprocess to match format ...\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(input_data)\n",
    "\n",
    "# Output: Array of predicted close prices\n",
    "```\n",
    "\n",
    "### **View Results:**\n",
    "```bash\n",
    "mlflow ui --backend-store-uri sqlite:///mlflow.db\n",
    "```\n",
    "Then open: http://localhost:5000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
